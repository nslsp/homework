{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用numpy搭建全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "  \n",
    "# 假设输入 X 和标签 y 已经给定  \n",
    "X = np.random.rand(100, 10)  # 100个样本，每个样本10个特征  \n",
    "y = np.random.randint(0, 2, 100)  # 假设是二分类问题  \n",
    "  \n",
    "# 定义网络参数  \n",
    "n_input = X.shape[1]  \n",
    "n_hidden = 5  \n",
    "n_output = 1  \n",
    "  \n",
    "# 初始化权重和偏置  \n",
    "W1 = np.random.randn(n_input, n_hidden)  \n",
    "b1 = np.zeros((1, n_hidden))  \n",
    "W2 = np.random.randn(n_hidden, n_output)  \n",
    "b2 = np.zeros((1, n_output))  \n",
    "  \n",
    "# 定义学习率  \n",
    "learning_rate = 0.01  \n",
    "  \n",
    "# 定义激活函数及其导数  \n",
    "def sigmoid(x):  \n",
    "    return 1 / (1 + np.exp(-x))  \n",
    "  \n",
    "def sigmoid_derivative(x):  \n",
    "    return x * (1 - x)  \n",
    "\n",
    "\n",
    "for epoch in range(1000):  \n",
    "    # 前向传播  \n",
    "    hidden_layer_input = np.dot(X, W1) + b1  \n",
    "    hidden_layer_activation = sigmoid(hidden_layer_input)  \n",
    "    output_layer_input = np.dot(hidden_layer_activation, W2) + b2  \n",
    "    predicted_y = sigmoid(output_layer_input)  \n",
    "      \n",
    "    # 计算损失  \n",
    "    loss = np.mean((predicted_y - y.reshape(-1, 1)) ** 2)  \n",
    "      \n",
    "    # 反向传播  \n",
    "    delta_output = predicted_y - y.reshape(-1, 1)  \n",
    "    d_W2 = np.dot(hidden_layer_activation.T, delta_output)  \n",
    "    d_b2 = np.sum(delta_output, axis=0, keepdims=True)  \n",
    "    delta_hidden = np.dot(delta_output, W2.T) * sigmoid_derivative(hidden_layer_activation)  \n",
    "    d_W1 = np.dot(X.T, delta_hidden)  \n",
    "    d_b1 = np.sum(delta_hidden, axis=0, keepdims=True)  \n",
    "      \n",
    "    # 更新权重和偏置  \n",
    "    W1 -= learning_rate * d_W1  \n",
    "    b1 -= learning_rate * d_b1  \n",
    "    W2 -= learning_rate * d_W2  \n",
    "    b2 -= learning_rate * d_b2  \n",
    "\n",
    "    # 损失  \n",
    "    if (epoch+1) % 100 == 0:  \n",
    "        print(f'Epoch {epoch+1}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用tensorflow搭建全连接神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf  \n",
    "  \n",
    "# 定义网络结构  \n",
    "model = tf.keras.Sequential([  \n",
    "    tf.keras.layers.Dense(5, activation='sigmoid', input_shape=(10,)),  \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])  \n",
    "  \n",
    "# 编译模型  \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  \n",
    "  \n",
    "# 使用随机数来作为标签\n",
    "X = np.random.rand(100, 10)  \n",
    "y = np.random.randint(0, 2, 100)  \n",
    "y = tf.keras.utils.to_categorical(y, 2)  \n",
    "  \n",
    "# 训练模型  \n",
    "model.fit(X, y, epochs=100)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
